{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-to-peer Learning Contribution Measure Model (Ebola dataset)\n",
    "This notebook implements a simple contribution model based on the notebook exemple of the DeAI repository. More precisely, it emulates a framework where `NUM_CLIENTS` clients are learning Ebola diagnosis (or prognosis) and average their models using a peer-to-peer learning setting (P2PL, i.e. without the orchestration of a central server)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import time\n",
    "\n",
    "# Custom functions\n",
    "from helpers import *\n",
    "\n",
    "# Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "from visualization import *\n",
    "plt.rc('legend', fontsize='small')\n",
    "plt.style.use('bmh')\n",
    "\n",
    "# Reproductibiity\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Console priniting option\n",
    "np.set_printoptions(precision=3, suppress=False, sign=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model \n",
    "`Ebola_Net` was developped by ... (link to repo?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Ebola_Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer-to-peer Learning Contribution Measure\n",
    "The following cells implement a peer-to-peer learning setting, i.e. where each user intitializes its own model and then,\n",
    "for $r=1,...,$ `NUM_ROUNDS`:\n",
    "\n",
    "1. Each client trains the model on its own data (`EPOCHS` times using batch of size `BATCH_SIZE`),\n",
    "2. Each client send its model to a subset of other users participating to the task (according to a communication graph),\n",
    "3. Each client recives the models from the other users,\n",
    "4. Each client evaluates the performance of the models on its own test datasets,\n",
    "5. Each client aggregates the models and update the contributions of each neighbouring user (in the communication graph)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (to be specified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topology\n",
    "NUM_CLIENTS = 4\n",
    "COMM_MATRIX = np.array([[1, 1, 1, 1],\n",
    "                        [1, 1, 1, 1],\n",
    "                        [1, 1, 1, 1],\n",
    "                        [1, 1, 1, 1]]) / NUM_CLIENTS\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "NUM_ROUNDS = 100\n",
    "EPOCHS = 1 #per round\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "THRESHOLD = 0.5 #for binary classificaltion\n",
    "CRITERION = nn.BCELoss()\n",
    "METRIC = 'loss_norm'\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataloaders\n",
    "\n",
    "train_loaders = # list of train datalader (1 per user) with batch_size=BATCH_SIZE\n",
    "test_loaders = # list of train datalader (1 per user) with batch_size=10*BATCH_SIZE\n",
    "test_loader_s = # datalader containing all the test dataset, with batch_size=10*BATCH_SIZE (only used for the ROC curve at the end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal losses and Shapley values for P2PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial model\n",
    "initial_model = Ebola_Net()\n",
    "client_models = [Ebola_Net() for _ in range(NUM_CLIENTS)]\n",
    "\n",
    "# coalition models and initialization\n",
    "coal_models_agg = {} \n",
    "global_coals = {}\n",
    "marg_coals = {}\n",
    "\n",
    "for i, weights in enumerate(COMM_MATRIX.transpose()):\n",
    "    \n",
    "    client_models[i].load_state_dict(initial_model.state_dict())\n",
    "    \n",
    "    # tuple containing all the users that sends their model to user i (including i)\n",
    "    global_coals[i] = tuple(np.nonzero(weights)[0])\n",
    "    # all the leave-one-out caolitions that i can make when aggregating the models it recieved.\n",
    "    for j in range(NUM_CLIENTS):\n",
    "        marg_coals[i, j] = tuple([k for k in global_coals[i] if k != j])\n",
    "    \n",
    "    for coal in powerset(global_coals[i]):\n",
    "        coal_models_agg[i, coal] = Ebola_Net()\n",
    "        coal_models_agg[i, coal].load_state_dict(initial_model.state_dict())\n",
    "\n",
    "# performance measures\n",
    "perf = initialize_perf((NUM_ROUNDS+1, NUM_CLIENTS)) # perf[0] contains the performance prior to learning\n",
    "marg_perf_agg = initialize_perf((NUM_ROUNDS, NUM_CLIENTS, NUM_CLIENTS)) \n",
    " \n",
    "for i in range(NUM_CLIENTS):\n",
    "    # untrained model performance\n",
    "    fill_perf_history(evaluate_model(client_models[i], test_loaders[i], CRITERION, THRESHOLD),\n",
    "                      perf, (0, i))\n",
    "    \n",
    "print('Prior performances ({}): {}'.format(METRIC, perf[METRIC][0, :]))\n",
    "\n",
    "# contribution\n",
    "SVa = np.zeros((NUM_ROUNDS, NUM_CLIENTS, NUM_CLIENTS))\n",
    "MLa = np.zeros((NUM_ROUNDS, NUM_CLIENTS, NUM_CLIENTS))\n",
    "\n",
    "\n",
    "# Iteration\n",
    "for r in range(NUM_ROUNDS):\n",
    "    t_start = time.time()\n",
    "    if VERBOSE:\n",
    "        print(\"------------------------------------\\nRound {}:\".format(r+1), end='')\n",
    "    else:\n",
    "        print(\"Round {}/{} (current {}: {})\".format(r+1, NUM_ROUNDS, METRIC, perf[METRIC][r, :]), end='\\r')\n",
    "        \n",
    "    # client update\n",
    "    loss = {}\n",
    "    for i, model in enumerate(client_models):\n",
    "        opt = optim.SGD(model.parameters(), lr=LR)\n",
    "        loss[i] = client_update(model, opt, CRITERION, train_loaders[i], epoch=EPOCHS)  \n",
    "    \n",
    "    # diffuse params across neighbors using different coalitions\n",
    "    diffuse_params(client_models, coal_models_agg, COMM_MATRIX)\n",
    "\n",
    "    # updating the client models with the aggregated model from the global coalitions\n",
    "    for i, model in enumerate(client_models):\n",
    "        model.load_state_dict(coal_models_agg[i, global_coals[i]].state_dict())\n",
    "    \n",
    "    # MLa\n",
    "    for i in range(NUM_CLIENTS):\n",
    "        \n",
    "        # Computing the performance of each client models\n",
    "        fill_perf_history(evaluate_model(client_models[i], test_loaders[i], CRITERION, THRESHOLD),\n",
    "                          perf, (r+1, i))\n",
    "        \n",
    "        # step 5. Updating the contributions     \n",
    "        # SVa\n",
    "        SVa[r, i, :] = SV_P2PL(NUM_CLIENTS, i, global_coals[i], coal_models_agg, test_loaders[i], METRIC, CRITERION, THRESHOLD)\n",
    "        \n",
    "        #MLa\n",
    "        for j in range(NUM_CLIENTS):\n",
    "            # marginal models (during aggregation) performance on marginal test datasets\n",
    "            fill_perf_history(evaluate_model(coal_models_agg[i, marg_coals[i, j]], test_loaders[i], CRITERION, THRESHOLD),\n",
    "                              marg_perf_agg, (r, i, j))\n",
    "        \n",
    "        MLa[r, i, :] = marg_perf_agg[METRIC][r, i, :] - perf[METRIC][r+1, i]\n",
    "    \n",
    "    t_round = time.time() - t_start\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\" ({:.1f}s)\".format(t_round))\n",
    "        print(\"Performance:\\n{} \".format(perf[METRIC][r+1]))\n",
    "        print(\"SVa:\")\n",
    "        print(\" -Total:\\n{}\".format(SVa[r]))\n",
    "        print(\" -Cumulative:\\n{}\".format(SVa.sum(0)))\n",
    "        print(\"MLa:\")\n",
    "        print(\" -Total:\\n{}\".format(MLa[r]))\n",
    "        print(\" -Cumulative:\\n{}\".format(MLa.sum(0)))\n",
    "\n",
    "\n",
    "print(\"------------------------------------\\nFinal performance ({}): {}\".format(METRIC, perf[METRIC][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training history vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotmetrics = ['loss_norm', 'accuracy', 'f1']\n",
    "\n",
    "# Model performance\n",
    "fig_perf = perfplots(perf, suptitle='Model Performance (server)', legends=legends, metrics=plotmetrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fig_ROC = ROC(coal_models_agg[0, global_coals[0]], test_loader_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contribution plot\n",
    "modes = ['round_maxmax', 'round_minmax', 'cum', 'minmax', 'maxmax']\n",
    "modes = ['round', 'cum']\n",
    "fig_SVa0 = contriplot(SVa[:,0,:], legends=legends, normalize=True, modes=modes, suptitle=\"Shapley Values at Aggregation\")\n",
    "fig_MLa0 = contriplot(MLa[:,0,:], legends=legends, normalize=True, modes=modes, suptitle=\"Marginal Losses at Aggregation\")\n",
    "fig_SVa1 = contriplot(SVa[:,1,:], legends=legends, normalize=True, modes=modes, suptitle=\"Shapley Values at Aggregation\")\n",
    "fig_MLa1 = contriplot(MLa[:,1,:], legends=legends, normalize=True, modes=modes, suptitle=\"Marginal Losses at Aggregation\")\n",
    "fig_SVa2 = contriplot(SVa[:,2,:], legends=legends, normalize=True, modes=modes, suptitle=\"Shapley Values at Aggregation\")\n",
    "fig_MLa2 = contriplot(MLa[:,2,:], legends=legends, normalize=True, modes=modes, suptitle=\"Marginal Losses at Aggregation\")\n",
    "fig_SVa3 = contriplot(SVa[:,3,:], legends=legends, normalize=True, modes=modes, suptitle=\"Shapley Values at Aggregation\")\n",
    "fig_MLa3 = contriplot(MLa[:,3,:], legends=legends, normalize=True, modes=modes, suptitle=\"Marginal Losses at Aggregation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import dill\n",
    "import os\n",
    "\n",
    "### Saving the relevant objects\n",
    "now = datetime.now()\n",
    "time = now.strftime('%d_%m_%Hh%M')\n",
    "subdir = \"P2PL_Ebola_{}/\".format(time)\n",
    "\n",
    "fig_dir = './saves/' + subdir + 'figures/'\n",
    "save_dir = './saves/' + subdir\n",
    "\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "    \n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_perf.savefig(fig_dir + 'perf.png')\n",
    "fig_ROC.savefig(fig_dir + 'ROC.png')\n",
    "fig_SVa0.savefig(fig_dir + 'SVa0.png')\n",
    "fig_MLa0.savefig(fig_dir + 'MLa0.png')\n",
    "fig_SVa1.savefig(fig_dir + 'SVa1.png')\n",
    "fig_MLa1.savefig(fig_dir + 'MLa1.png')\n",
    "fig_SVa2.savefig(fig_dir + 'SVa2.png')\n",
    "fig_MLa2.savefig(fig_dir + 'MLa2.png')\n",
    "fig_SVa3.savefig(fig_dir + 'SVa3.png')\n",
    "fig_MLa3.savefig(fig_dir + 'MLa3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session(save_dir + 'variables.pckl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "directory = './saves/FL_n4_r100_25_05_23h42/'\n",
    "dill.load_session(directory + 'variables.pckl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
