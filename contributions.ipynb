{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Contribution Measure Model\n",
    "This notebook implements a simple contribution model based on the notebook exemple of the DeAI repository. More precisely, it emulates a framework where `num_clients` clients are learning MNIST classification and diffusing their parameters on a graph representing by a communication matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Reproductibiity\n",
    "SEED = 123456789\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Print option\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This cell is a copy-paste of the corresponding cell in the DeAI (only without using cuda)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(2048, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    \"\"\"Train a client_model on the train_loder data.\"\"\"\n",
    "    client_model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            #data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def diffuse_params(client_models, communication_matrix):\n",
    "    \"\"\"Diffuse the models with their neighbors.\"\"\"\n",
    "    if client_models:\n",
    "      client_state_dicts = [model.state_dict() for model in client_models]\n",
    "      keys = client_state_dicts[0].keys()\n",
    "    for model, weights in zip(client_models, communication_matrix):\n",
    "        neighbors = np.nonzero(weights)[0]\n",
    "        model.load_state_dict(\n",
    "            {\n",
    "                key: torch.stack(\n",
    "                    [weights[j]*client_state_dicts[j][key] for j in neighbors],\n",
    "                    dim=0,\n",
    "                ).sum(0) / weights.sum() \n",
    "                for key in keys\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "def average_models(global_model, client_models):\n",
    "    \"\"\"Average models across all clients.\"\"\"\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k] for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    \"\"\"Compute loss and accuracy of a single model on a data_loader.\"\"\"\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            #data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    loss /= len(data_loader.dataset)\n",
    "    acc = correct / len(data_loader.dataset)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "def evaluate_many_models(models, data_loader):\n",
    "  \"\"\"Compute average loss and accuracy of multiple models on a data_loader.\"\"\"\n",
    "  num_nodes = len(models)\n",
    "  losses = np.zeros(num_nodes)\n",
    "  accuracies = np.zeros(num_nodes)\n",
    "  for i in range(num_nodes):\n",
    "    losses[i], accuracies[i] = evaluate_model(models[i], data_loader)\n",
    "  return losses, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Learning Contribution Measure\n",
    "The following cells implement the case where the central server intitialize the model and the contributions $c_i^{(0)}$ of each user (to zero).\n",
    "\n",
    "Then, for $t=1,...,r$ with $r=$ `num_rounds`:\n",
    "1. The central server evaluates the accuracy $\\hat{\\theta}^{(t)}_{prior}$ of the model on a test datasets (theoretically representing the distribution across users, i.e. the overall tasks),\n",
    "3. The central server distributes the model to **all** the $n=$ `num_clients` clients,\n",
    "4. Each client evaluates the accuracy $\\theta^{(t)}_{i,prior}$ of the model on its own data (i.e. its own distribution),\n",
    "5. Each client learns the model on its own data (`epochs` times using batch of size `batch_size`),\n",
    "6. Each client evaluates the new accuracy $\\theta^{(t)}_{i,post}$ of the model on its own data,\n",
    "7. Each client sends the trained model $\\theta^{(t)}_{i,post}$, and $\\theta^{(t)}_{i,prior} $ to the central server,\n",
    "8. The central server evaluates each client model on its test dataset and compute their accuracy $\\hat{\\theta}^{(t)}_{i,post}$,\n",
    "9. The central server aggregates the models and update the contributions of each user:\n",
    "$$c_i^{(t)} = g\\left(\\hat{\\theta}^{(t)}_{prior}, \\{ \\hat{\\theta}^{(t)}_{i, post}, \\theta^{(t)}_{i,prior}, \\theta^{(t)}_{i,post}, c_i^{(t-1)}\\}_{1\\leq i \\leq n}\\right)$$ where $g$ is the contribution function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplicative version of $g(...)$:\n",
    "$$c_i^{(t)} = c_i^{(t-1)}  + \\theta^{(t)}_{i,prior} (\\hat{\\theta}^{(t)}_{i,post} - \\hat{\\theta}^{(t)}_{prior}) \\left[ 1 - \\frac{|(\\theta^{(t)}_{i,post} - \\theta^{(t)}_{i,prior}) - (\\hat{\\theta}^{(t)}_{i,post} - \\hat{\\theta}^{(t)}_{prior})|}{\\sum_{j=1}^n |(\\theta^{(t)}_{j,post} - \\theta^{(t)}_{j,prior}) - (\\hat{\\theta}^{(t)}_{j,post} - \\hat{\\theta}^{(t)}_{prior})|} \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contribution functions\n",
    "\n",
    "def g_mult(theta_prior_s, thetas_post_s, thetas_prior, thetas_post, c_old):\n",
    "    delta_global = thetas_post_s - theta_prior_s\n",
    "    delta_global[delta_global < 0] = 0\n",
    "    \n",
    "    delta_clients = thetas_post - thetas_prior\n",
    "    \n",
    "    penalty = delta_clients - delta_global\n",
    "    #penalty[penalty < 0] = 0\n",
    "    \n",
    "    if np.sum(np.abs(penalty)) < 1e-6:\n",
    "        c = thetas_prior * c_old + delta_global\n",
    "    else:\n",
    "        c =  c_old + thetas_prior * delta_global * (1 -  np.abs(penalty)/np.sum(np.abs(penalty)))\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network topology\n",
    "num_clients = 5\n",
    "comm_matrix = np.ones((num_clients, num_clients)) / num_clients\n",
    "\n",
    "# Training parameters\n",
    "num_rounds = 5\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "# Loading the train data\n",
    "traindata_full = datasets.MNIST(root='./data', \n",
    "                           train=True, \n",
    "                           download=True, \n",
    "                           transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "\n",
    "# smaller dataset for code testing\n",
    "#N_full = len(traindata_full)\n",
    "#N = 1000 * num_clients\n",
    "#traindata = torch.utils.data.random_split(traindata_full, [N, N_full - N])[0]\n",
    "traindata = traindata_full\n",
    "\n",
    "\n",
    "traindata_split = torch.utils.data.random_split(traindata,\n",
    "                                                [int(len(traindata) / num_clients) for _ in range(num_clients)])\n",
    "\n",
    "train_loaders = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "\n",
    "# Loading the test data\n",
    "testdata_full = datasets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           download=True, \n",
    "                           transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "\n",
    "# smaller dataset for code testing\n",
    "#N_full_te = len(testdata_full)\n",
    "#N_te = 1000 * num_clients\n",
    "#testdata = torch.utils.data.random_split(testdata_full, [N_te, N_full_te - N_te])[0]\n",
    "testdata = testdata_full\n",
    "\n",
    "\n",
    "testdata_split = torch.utils.data.random_split(testdata,\n",
    "                                               [int(len(testdata) / num_clients) for _ in range(num_clients)])\n",
    "\n",
    "test_loaders = [torch.utils.data.DataLoader(x, batch_size=10*batch_size, shuffle=True) for x in testdata_split]\n",
    "\n",
    "# Full dataset for the server (_s for server)\n",
    "test_loader_s = torch.utils.data.DataLoader(testdata, batch_size=10*batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emulating federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "\tPrior performance on server side:  0.114\n",
      "\tPrior performance on client side:  [0.115 0.114 0.117 0.105 0.118]\n",
      "\tPosterior performance on client side:  [0.937 0.941 0.934 0.925 0.957]\n",
      "\tPosterior performance on server side:  [0.938 0.944 0.942 0.929 0.952]\n",
      "\tTotal contributions: [0.087 0.082 0.046 0.064 0.098] \t Normalized: [0.231 0.216 0.122 0.17  0.261]\n",
      "1-th round\n",
      "\tPrior performance on server side:  0.9539\n",
      "\tPrior performance on client side:  [0.952 0.956 0.951 0.951 0.96 ]\n",
      "\tPosterior performance on client side:  [0.966 0.959 0.962 0.957 0.964]\n",
      "\tPosterior performance on server side:  [0.968 0.962 0.965 0.963 0.959]\n",
      "\tTotal contributions: [0.1   0.085 0.056 0.07  0.103] \t Normalized: [0.241 0.206 0.135 0.169 0.248]\n",
      "2-th round\n",
      "\tPrior performance on server side:  0.9737\n",
      "\tPrior performance on client side:  [0.974 0.976 0.973 0.971 0.976]\n",
      "\tPosterior performance on client side:  [0.974 0.966 0.971 0.965 0.968]\n",
      "\tPosterior performance on server side:  [0.968 0.965 0.972 0.971 0.967]\n",
      "\tTotal contributions: [0.1   0.085 0.056 0.07  0.103] \t Normalized: [0.241 0.206 0.135 0.169 0.248]\n",
      "3-th round\n",
      "\tPrior performance on server side:  0.9779\n",
      "\tPrior performance on client side:  [0.976 0.978 0.977 0.979 0.981]\n",
      "\tPosterior performance on client side:  [0.971 0.978 0.974 0.967 0.973]\n",
      "\tPosterior performance on server side:  [0.972 0.972 0.972 0.97  0.969]\n",
      "\tTotal contributions: [0.1   0.085 0.056 0.07  0.103] \t Normalized: [0.241 0.206 0.135 0.169 0.248]\n",
      "4-th round\n",
      "\tPrior performance on server side:  0.9818\n",
      "\tPrior performance on client side:  [0.979 0.987 0.981 0.981 0.982]\n",
      "\tPosterior performance on client side:  [0.978 0.985 0.975 0.973 0.981]\n",
      "\tPosterior performance on server side:  [0.98  0.981 0.976 0.977 0.978]\n",
      "\tTotal contributions: [0.1   0.085 0.056 0.07  0.103] \t Normalized: [0.241 0.206 0.135 0.169 0.248]\n",
      "\tFinal performance:  0.9847\n"
     ]
    }
   ],
   "source": [
    "# step 0. Initialization\n",
    "global_model = Net()\n",
    "contributions = np.zeros((num_rounds + 1, num_clients))\n",
    "\n",
    "# server side\n",
    "theta_prior_s = np.zeros(num_rounds)\n",
    "test_loss_prior_s = np.zeros(num_rounds)\n",
    "thetas_post_s = np.zeros((num_rounds, num_clients))\n",
    "test_losses_post_s = np.zeros((num_rounds, num_clients))\n",
    "\n",
    "# client side\n",
    "thetas_prior = np.zeros((num_rounds, num_clients))\n",
    "test_losses_prior = np.zeros((num_rounds, num_clients))\n",
    "thetas_post = np.zeros((num_rounds, num_clients))\n",
    "test_losses_post = np.zeros((num_rounds, num_clients))\n",
    "\n",
    "\n",
    "\n",
    "# Iteration\n",
    "for r in range(num_rounds):\n",
    "    print('%d-th round' % (r))\n",
    "    \n",
    "    # step 1. Evaluating the prior model on the global test dataset\n",
    "    test_loss_prior_s[r], theta_prior_s[r] = evaluate_model(global_model, test_loader_s)\n",
    "    print(\"\\tPrior performance on server side: \", theta_prior_s[r])\n",
    "\n",
    "\n",
    "    # step 2: Sending the model (emulating)\n",
    "    client_models = [Net() for _ in range(num_clients)]\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "\n",
    "    # step 3. Evaluating the prior model on each local test dataset\n",
    "    for i in range(num_clients):\n",
    "        test_losses_prior[r, i], thetas_prior[r, i] = evaluate_model(client_models[i], test_loaders[i])\n",
    "\n",
    "    print(\"\\tPrior performance on client side: \", thetas_prior[r, :])\n",
    "\n",
    "    \n",
    "    # step 4. Learning on client side\n",
    "    opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]\n",
    "    loss = 0\n",
    "    for i in range(num_clients):\n",
    "        loss += client_update(client_models[i], opt[i], train_loaders[i], epoch=epochs)\n",
    "        \n",
    "    #print('\\tAverage train loss %0.3g' % (loss / num_clients))\n",
    "\n",
    "    \n",
    "    # step 5. Evaluating the posterior model on each local test dataset\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        test_losses_post[r, i], thetas_post[r, i] = evaluate_model(client_models[i], test_loaders[i])\n",
    "    \n",
    "    print(\"\\tPosterior performance on client side: \", thetas_post[r, :])\n",
    "    \n",
    "    \n",
    "    # step 6. Sending the local models to the server (nothing to do)\n",
    "\n",
    "\n",
    "    # step 7. Evaluating the posterior models on the global test dataset\n",
    "    for i in range(num_clients):\n",
    "        test_losses_post_s[r, i], thetas_post_s[r, i] = evaluate_model(client_models[i], test_loader_s)\n",
    "    \n",
    "    print(\"\\tPosterior performance on server side: \", thetas_post_s[r, :])\n",
    "    \n",
    "    # step 8. Aggregating the models and updating the contributions\n",
    "    average_models(global_model, client_models)\n",
    "    contributions[r+1,:]= g_mult(theta_prior_s[r], thetas_post_s[r,:], thetas_prior[r,:], thetas_post[r,:], contributions[r,:])\n",
    "    \n",
    "    print(\"\\tTotal contributions: {c_tot} \\t Normalized: {c}\".format(c_tot=contributions[r+1, :], c=contributions[r+1, :]/np.sum(contributions[r+1, :])))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "test_loss_final_s, theta_final_s = evaluate_model(global_model, test_loader_s)\n",
    "print(\"\\tFinal performance: \", theta_final_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
